# Web3Eye

## feature

### 工程特性
- [x] 支持k8s部署
  - [x] 服务发现(使用k8s的svc)和配置管理（使用toml）
- [x] 支持多副本
- [ ] unit-test
- [x] 使用一个工程管理代码
- [ ] 资源性能模型分析工具
- [x] Api接口说明：swagger
  
#### CICD

- [ ] Docker Compose
- [x] K8s
- [x] Jenkins
Golang
- [x] Verify
  - [x] lint
  - [x] spell
  - [x] build
- [ ] Test
- [x] Dockerfile

Python
- [ ] Verify
  - [ ] lint
  - [ ] spell
  - [ ] build
- [ ] Test
- [x] Dockerfile

Vue
- [x] Verify
  - [x] lint
  - [x] spell
  - [x] build
- [ ] Test
- [x] Dockerfile

#### NFT-META

存储nft信息

- [x] 创建NFT信息
- [x] 以图搜索nft信息
- [x] 与milvus交互（创建collection及向量创建、删除、查询、搜索等）
- [x] milvus交互优化，使用官方的代码生成器生成交互代码,官方并无
- [x] 记录扫描过的高度及状态
- [ ] 解析错误的过程记录
- [x] 管理kafka的topic(创建、删除)
- [ ] 创建和删除资源成对
  - [ ] 创建token记录时需要生成milvus的一条记录，同时删除时也需要将milvus中的记录删除
- [x] 支持重入（不会产生多条重复数据）

#### BLOCK-ETL

从链上索引nft相关信息

- [x] 自动索引NFT信息(转账信息)
- [x] 索引合约创建信息
- [ ] 索引NFT-mint信息
- [x] 补齐未进行交易的NFT信息(主要补齐资源地址)
- [ ] 支持以chain-contract-tokenid生成一个identify帮助快速查询，主要方便关系表的使用
- [x] 按照链类型组织代码
- [x] eth数据处理
  - [x] 索引代码降低耦合
- [ ] 可控抓取链上数据，控制同时抓取数据的并发量，防止资源消耗不可控
- [x] 热查询（经常会用到的固定信息）缓存进redis
  - [x] tokentransfer中用到的identifier
  - [x] 是否已存在contract
  - [x] 区块高度对应时间戳

#### NFT-MEDIA

解析nft资产带的媒体资源

- [ ] 自动解析资源地址

#### IMAGE-CONVERT

- [x] 图片向量化
  - [ ] Jpeg、Png、Avif
- [x] http图片向量化
- [x] ipfs图片向量化（采用http方式解析）
- [ ] ipfs图片向量化（采用IPFS方式解析）
- [ ] 链上图片数据向量化（如base64/svg格式）
- [ ] 架构更换或打包优化（现在的docker镜像太大）

### Web3Eye 目录结构

服务一（golang）:

- [ ] 代码
- [ ] Dockerfile、K8s_yaml
- [ ] Script
  - [ ] Build
  - [ ] Test
  
服务二（golang）  
服务三（python）  
服务四（typescript）  

公共代码:

- [ ] network
- [ ] math
- [ ] ...

hack:

- [ ] Verify (Lint、Spell...)
- [ ] ProjectManager(ToolsInstall\ Message\abi-gen\Deps ...)

Makefile:  

- [ ] Verify
- [ ] Test
- [ ] Build
- [ ] Run
- [ ] ProjectManager

DockerCompose

Jenkinsfile  

## 第三方组件搭建方案

### mysql

### milvus

### redis

### kafka

## 问题？

1.前端form传文件是否底层是base64 close
现在这个问题不用讨论，直接使用http的文件上传

2.kafka资源问题，保证稳定-放到集群后没啥问题 close 已由pulsar替代
  已经扩展kafka成为3节点集群，需要后续观察
  经过观察Kafka在k8s中部署集群，出现故障后比较难恢复，新安装也很难组成集群

3.nft-meta向block-etl发送任务，但是在网络不稳定时block-etl重启后nft-meta已经将任务发送完成，导致block-etl以为任务已经完成，不消费kafka中的任务
后续用block为粒度处理，保证任务原子性

4.研究僵尸进程问题

5.NFT-Meta放BlockNumber时，未上锁，容易导致错误
 已经上锁但是未测试

6.Jenkins 部署时已有的对象时没办法通过apply来更新，考虑replace

7.Jenkins 中打tag后relase一个版本有bug，因为在release时目标项目是可选的，导致子项目release出来的tag会有问题
 将阶段分为Build-Tag-Release-Deploy，分开自取，可指定版本部署，不指定取最近最复合部署

8.Python下载解析资源问题
  base64/svg 类型无法支持
  一些url无法被下载，但是可以在浏览器中访问到图片，例如：<https://storage.kumaleon.com/0x8270fc3b2d23de703b265b2abe008883954fea8e/2093.png>

9.提高块儿转存稳定性，保证每一块儿的数据都能转存
  考虑在转存中采用多阶段确认机制  

10.资源原子性问题
  删除了同步任务 涉及的topic milvus等资源需要同步删除

11.不同文件格式之间的内容相似度问题，比如jpeg和avif同样的图片相似度会如何？
  初步测试了jpg、png、jpeg之间的相似度，欧式距离小于0.1，但还是不可避免的出现同一张图距离不为零。
  要是追求完美的相似度，可将图片格式都转成一致的再转换成向量。
  目前在转向量时PNG和SVG会做检测和转换
  
## Error

1.BlockETL存在重复存key的问题，需要排查

重复存Key是因为放在redis中的锁时间过短，导致重复create同一条数据，这里只是单纯延长锁的时长来解决这个问题

2.BlockETL转存是remark过大

将remark转换成text类型

3.容器中日志文件未在配置文件指定的日志路径上

可能是因为残存之前的日志文件配置导致的

4.需要仔细查看converter解析每一种资源的情况，比如svg的支持，对会发生307资源的解析等


## 解析列表

- 图片：
  - 支持： png，jpg，jpeg，base64svg
  - 未支持： svg、gif、webp